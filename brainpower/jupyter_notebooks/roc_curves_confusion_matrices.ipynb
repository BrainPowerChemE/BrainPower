{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bebd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statistics import stdev\n",
    "import statsmodels\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import imblearn\n",
    "import sys\n",
    "import imblearn\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "import scipy.stats\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statistics import stdev\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from itertools import combinations\n",
    "\n",
    "import sklearn.ensemble\n",
    "from itertools import cycle\n",
    "import time\n",
    "from sklearn.metrics import RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c5008",
   "metadata": {},
   "source": [
    "# Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94d1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_features = ['AK1C1','TAU', '1433G', 'SCUB1', 'FMOD', 'AMYP', 'CRIS3', \n",
    "                'MYDGF', 'RARR2', 'ATS8', 'PGK1', '1433Z', 'SV2A', 'TRH', 'GUAD', \n",
    "                'HV69D', 'CO7', 'SERC']\n",
    "\n",
    "list_features_plus_biomarkers = ['AK1C1','TAU', '1433G', 'SCUB1', 'FMOD', 'AMYP', 'CRIS3', \n",
    "                'MYDGF', 'RARR2', 'ATS8', 'PGK1', '1433Z', 'SV2A', 'TRH', 'GUAD', \n",
    "                'HV69D', 'CO7', 'SERC', 'AB42/AB40', 'Ttau (pg/ml)']\n",
    "\n",
    "list_features_plus_ab42 = ['AK1C1','TAU', '1433G', 'SCUB1', 'FMOD', 'AMYP', 'CRIS3', \n",
    "                'MYDGF', 'RARR2', 'ATS8', 'PGK1', '1433Z', 'SV2A', 'TRH', 'GUAD', \n",
    "                'HV69D', 'CO7', 'SERC', 'AB42/AB40']\n",
    "\n",
    "list_features_plus_tau = ['AK1C1','TAU', '1433G', 'SCUB1', 'FMOD', 'AMYP', 'CRIS3', \n",
    "                'MYDGF', 'RARR2', 'ATS8', 'PGK1', '1433Z', 'SV2A', 'TRH', 'GUAD', \n",
    "                'HV69D', 'CO7', 'SERC', 'Ttau (pg/ml)']\n",
    "\n",
    "\n",
    "list_features_ab42 = ['AB42/AB40']\n",
    "\n",
    "list_features_tau = ['Ttau (pg/ml)']\n",
    "\n",
    "list_features_both = ['AB42/AB40', 'Ttau (pg/ml)']\n",
    "\n",
    "feature_options=[list_features, list_features_plus_ab42, list_features_plus_tau, \n",
    "                 list_features_plus_biomarkers, \n",
    "                 list_features_ab42, list_features_tau, list_features_both]\n",
    "\n",
    "classes_of_interest=['Healthy', 'PD_MCI_LBD', 'PD', 'AD_MCI']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95848fc",
   "metadata": {},
   "source": [
    "# Functions I used\n",
    "I copied and pasted the functions I needed directly in this notebook-- but once this is finalized, I would import them instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1595a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_scale_and_nan(df, nan_decision='drop'):\n",
    "    features = list(df.select_dtypes(include='float64'))\n",
    "    cat = list(df.select_dtypes(include='object'))\n",
    "    scaler = sklearn.preprocessing.StandardScaler().fit(df[features])\n",
    "    df_cont = pd.DataFrame(data=scaler.transform(df[features]), columns=features)\n",
    "    df_cat = pd.DataFrame(data=df[cat], columns=cat)\n",
    "    \n",
    "    df = pd.concat([df_cat,df_cont],axis=1)\n",
    "    \n",
    "    if nan_decision == 'mean':\n",
    "        for feature in features:\n",
    "            df[feature].fillna((df[feature].mean()), inplace=True)\n",
    "    elif nan_decision == 'drop':\n",
    "            df = df.dropna(axis=1)\n",
    "    elif nan_decision == 'impute':\n",
    "        imputer = missingpy.MissForest() #must be in shape of n_samples by n_features\n",
    "        df = imputer.fit_transform(df[:, 1:]) # impute NaNs with existing numerical vals\n",
    "        df.insert(0, \"group\", df[:, 0], allow_duplicates=True) # reinsert the nominal vals\n",
    "    elif nan_decision == 'replace_ones': \n",
    "        df.fillna(value=1)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def over_under(df_train,cat_in_excess='Healthy',target='group',randomstate=np.random.randint(0,4294967295)):\n",
    "    \"\"\"\n",
    "    Takes dataframe(s) with only the target value and float64 features\n",
    "    This function is to balance the samples in an imbalanced training dataset that has one category in excess, with additional categories more near each other\n",
    "    The categories below the category in excess will be oversampled to equality, then the category in excess will be undersampled to equality\n",
    "    ---Parameters---\n",
    "    df_train: the training dataframe\n",
    "    cat_in_excess: the category which is present in excess, far above the other categories\n",
    "    target: target column in the dataframe\n",
    "    randomstate: if chosen, this will the random state for the sampling. Default: None, numpy random integer method between 0 and 4294967295, the range of the sampling module used\n",
    "    randomstate_sampler: the number of loops to run to compare random states starting from \n",
    "    \"\"\"\n",
    "        \n",
    "    # Drop the excessive category and oversample minority to the intermediate category\n",
    "    df_train_no_excess = df_train[df_train.group != cat_in_excess]\n",
    "    over_sampler = imblearn.over_sampling.RandomOverSampler(random_state=randomstate)\n",
    "    X_train = df_train_no_excess.drop(columns=target)\n",
    "    y_train = df_train_no_excess[target]\n",
    "    X_train_over, y_train_over = over_sampler.fit_resample(X_train,y_train)\n",
    "    df_train_over = pd.concat([y_train_over,X_train_over],axis=1)\n",
    "\n",
    "    # Re-introduce the excessive category and undersample the majority to the minority\n",
    "    df_train_excess = pd.concat([df_train_over,df_train[df_train[target] == cat_in_excess]])\n",
    "    under_sampler = imblearn.under_sampling.RandomUnderSampler(random_state=randomstate)\n",
    "    X_train = df_train_excess.drop(columns=target)\n",
    "    y_train = df_train_excess[target]\n",
    "    X_train_under, y_train_under = under_sampler.fit_resample(X_train,y_train)\n",
    "    df_train_eq = pd.concat([y_train_under,X_train_under],axis=1)\n",
    "    \n",
    "    return df_train_eq\n",
    "\n",
    "def apply_ml_model(dev,classifier,scoring_method='balanced_accuracy',target='group', cv=10, feature_list=list_features):\n",
    "    \"\"\"\n",
    "    Finds the score for different ML classifiers\n",
    "    Takes a dataframe with only target and feature columns\n",
    "    dev : the development dataframe with a single categorical target column and float64 features\n",
    "    classifier: ML classifier to test.\n",
    "        options: \"random_forest', \"naive_bayes\", \"decision_tree\"\n",
    "    scoring_method: method of scoring the classifier\n",
    "        run sklearn.metrics.get_scorer_names() to get a list of scoring methods\n",
    "    target: target categorical column\n",
    "    cv: folds to run in evaluation. takes integers or 'max': will run maximum number of folds = # of samples in categories\n",
    "    \"\"\"\n",
    "    # define predictor and response variables\n",
    "    X = dev[feature_list]\n",
    "    y = dev[target]\n",
    "    \n",
    "    # check that the data has equal number of categories in training data\n",
    "    counts_list = list(dev['group'].value_counts())\n",
    "    assert len(set(counts_list)) == 1, 'training data should contain equal quantities of categories. run bp_preprocessing.over_under() or other balancer'\n",
    "    \n",
    "    \n",
    "    # choose model based on user input\n",
    "    if classifier == \"random_forest\": \n",
    "        model = sklearn.ensemble.RandomForestClassifier()\n",
    "    elif classifier == \"naive_bayes\":  \n",
    "        model = sklearn.naive_bayes.GaussianNB()\n",
    "    elif classifier == \"decision_tree\": \n",
    "        model = sklearn.tree.DecisionTreeClassifier()\n",
    "    elif classifier == \"xgboost\": \n",
    "        model = XGBClassifier()\n",
    "    else: \n",
    "        print(\"wrong classifier named entered\")\n",
    "    #define cv quantity:\n",
    "    if type(cv) == int:\n",
    "        pass\n",
    "    elif cv == 'max':\n",
    "        cv = counts_list[0]\n",
    "    else:\n",
    "        raise TypeError('Enter an integer or \"max\" as a string')\n",
    "        \n",
    "    scores = cross_val_score(model, X, y, scoring=scoring_method,cv=cv)\n",
    "    mean_score = np.mean(absolute(scores))\n",
    "    std = np.std(scores)\n",
    "    stats_list = [cv, scores, mean_score, std , model, scoring_method, feature_list[-2:]]\n",
    "    stats_df = pd.DataFrame(data=[stats_list], columns=['folds','scores','abs_avg_score','std','model','scoring_method', 'features'])\n",
    "    \n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfab5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_biomarkers_as_features(compiled_metadata, data_dev, data_test): \n",
    "\n",
    "    compiled_metadata = compiled_metadata.set_index(\"Public Sample ID\")\n",
    "    compiled_metadata = compiled_metadata.sort_index()\n",
    "    compiled_metadata = compiled_metadata.dropna(axis = 0, how = 'all')\n",
    "    compiled_metadata = compiled_metadata[(compiled_metadata.Condition != 'Golden West CSF Batch QC')]\n",
    "    compiled_metadata = compiled_metadata[compiled_metadata.Condition != 'Lumbar CSF Pool Batch Ref']\n",
    "\n",
    "    compiled_metadata = compiled_metadata[['Condition', 'Ttau (pg/ml)', 'AB42 (pg/ml)']]\n",
    "    \n",
    "    dict_AB42_ratio = {}\n",
    "    for i, j in zip(compiled_metadata.index, compiled_metadata['AB42 (pg/ml)']): \n",
    "        dict_AB42_ratio[i]= j\n",
    "\n",
    "    dict_tau = {}\n",
    "    for i, j in zip(compiled_metadata.index, compiled_metadata['Ttau (pg/ml)']): \n",
    "        dict_tau[i]= j\n",
    "\n",
    "    data_dev['AB42/AB40'] = data_dev['assay_ID'].map(dict_AB42_ratio)\n",
    "    data_dev['Ttau (pg/ml)'] = data_dev['assay_ID'].map(dict_tau)\n",
    "\n",
    "    data_test['AB42/AB40'] = data_test['assay_ID'].map(dict_AB42_ratio)\n",
    "    data_test['Ttau (pg/ml)'] = data_test['assay_ID'].map(dict_tau)\n",
    "    \n",
    "    return data_dev, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eccd7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data_dev, data_test): \n",
    "    data_dev = handle_scale_and_nan(data_dev)\n",
    "    data_test = handle_scale_and_nan(data_test)\n",
    "    data_dev = data_dev.drop(columns='assay_ID')\n",
    "    data_test = data_test.drop(columns='assay_ID')\n",
    "    data_dev = over_under(data_dev) #split groups equally \n",
    "    return data_dev, data_test\n",
    "\n",
    "def make_confusion_mtrx(dev, data_test, features=list_features):\n",
    "    test_X = data_test[list_features]\n",
    "    test_y = data_test['group']\n",
    "\n",
    "    dev_X = dev[list_features]\n",
    "    dev_y = dev.iloc[:,0] # 0th column is our target\n",
    "\n",
    "    model = sklearn.ensemble.RandomForestClassifier()\n",
    "    model.fit(dev_X, dev_y) \n",
    "    print('score=', sklearn.metrics.balanced_accuracy_score(test_y, model.predict(test_X)))\n",
    "    ConfusionMatrixDisplay.from_estimator(model, test_X, test_y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b4f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curves_one_vs_rest(data_dev, data_test, list_features=list_features_plus_biomarkers):\n",
    "    data_dev, data_test = pre_process_data(data_dev, data_test)\n",
    "    \n",
    "    dev = data_dev[list_features]\n",
    "    dev.insert(0, \"group\", data_dev['group'], True)\n",
    "    \n",
    "    X_test = data_test[list_features]\n",
    "    y_test = data_test['group']\n",
    "\n",
    "    X_train = dev.iloc[:,1:] \n",
    "    y_train = dev.iloc[:,0] # 0th column is our target\n",
    "\n",
    "\n",
    "    classifier = sklearn.ensemble.RandomForestClassifier()\n",
    "    y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "    label_binarizer = LabelBinarizer().fit(y_train)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    # store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", 'red'])\n",
    "    for class_id, color in zip(range(4), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            name=f\"ROC curve for {classes_of_interest[class_id]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"ROC curve for chance level (AUC = 0.5)\")\n",
    "    plt.axis(\"square\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    if len(list_features)==20: \n",
    "        plt.title(f\"One-vs-Rest ROC curves, using 18 features + {list_features[-2:]}\")\n",
    "    elif len(list_features)==18:\n",
    "        plt.title(f\"One-vs-Rest ROC curves, using 18 features\")\n",
    "    elif len(list_features)==19:\n",
    "        plt.title(f\"One-vs-Rest ROC curves, using 18 features + {list_features[-1:]}\")\n",
    "    else: \n",
    "        plt.title(f\"One-vs-Rest ROC curves, using {list_features}\")\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e69f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_one_vs_one(data_dev, data_test, list_features): \n",
    "    pair_scores = []\n",
    "    mean_tpr = dict()\n",
    "    pair_list = list(combinations(np.unique(classes_of_interest), 2))\n",
    "    \n",
    "    data_dev, data_test = pre_process_data(data_dev, data_test)\n",
    "    dev = data_dev[list_features]\n",
    "    dev.insert(0, \"group\", data_dev['group'], True)\n",
    "    \n",
    "    X_test = data_test[list_features]\n",
    "    y_test = data_test['group']\n",
    "\n",
    "    X_train = dev.iloc[:,1:] \n",
    "    y_train = dev.iloc[:,0] # 0th column is our target\n",
    "\n",
    "\n",
    "    classifier = sklearn.ensemble.RandomForestClassifier()\n",
    "    y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "    \n",
    "    label_binarizer = LabelBinarizer().fit(y_train)\n",
    "    \n",
    "    for ix, (label_a, label_b) in enumerate(pair_list):\n",
    "\n",
    "        a_mask = y_test == label_a\n",
    "        b_mask = y_test == label_b\n",
    "        ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "        a_true = a_mask[ab_mask]\n",
    "        b_true = b_mask[ab_mask]\n",
    "\n",
    "        idx_a = np.flatnonzero(label_binarizer.classes_ == label_a)[0]\n",
    "        idx_b = np.flatnonzero(label_binarizer.classes_ == label_b)[0]\n",
    "\n",
    "        fpr_a, tpr_a, _ = roc_curve(a_true, y_score[ab_mask, idx_a])\n",
    "        fpr_b, tpr_b, _ = roc_curve(b_true, y_score[ab_mask, idx_b])\n",
    "\n",
    "        fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "        mean_tpr[ix] = np.zeros_like(fpr_grid)\n",
    "        mean_tpr[ix] += np.interp(fpr_grid, fpr_a, tpr_a)\n",
    "        mean_tpr[ix] += np.interp(fpr_grid, fpr_b, tpr_b)\n",
    "        mean_tpr[ix] /= 2\n",
    "        mean_score = auc(fpr_grid, mean_tpr[ix])\n",
    "        pair_scores.append(mean_score)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        plt.plot(\n",
    "            fpr_grid,\n",
    "            mean_tpr[ix],\n",
    "            label=f\"Mean {label_a} vs {label_b} (AUC = {mean_score :.2f})\",\n",
    "            linestyle=\":\",\n",
    "            linewidth=4,\n",
    "        )\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            a_true,\n",
    "            y_score[ab_mask, idx_a],\n",
    "            ax=ax,\n",
    "            name=f\"{label_a} as positive class\",\n",
    "        )\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            b_true,\n",
    "            y_score[ab_mask, idx_b],\n",
    "            ax=ax,\n",
    "            name=f\"{label_b} as positive class\",\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "        plt.axis(\"square\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "        if len(list_features)==20: \n",
    "            plt.title(f\"{label_a} vs {label_b} ROC curves, using 18 features + {list_features[-2:]}\")\n",
    "        elif len(list_features)==18:\n",
    "            plt.title(f\"{label_a} vs {label_b} ROC curves, using 18 features\")\n",
    "        elif len(list_features)==19:\n",
    "            plt.title(f\"{label_a} vs {label_b} ROC curves, using 18 features + {list_features[-1:]}\")\n",
    "        else: \n",
    "            plt.title(f\"{label_a} vs {label_b} ROC curves, using {list_features}\")\n",
    "        \n",
    "            \n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdb05e",
   "metadata": {},
   "source": [
    "# Importing data\n",
    "Import dev and test data from split_data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b81b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>AK1C1</th>\n",
       "      <th>TAU</th>\n",
       "      <th>1433G</th>\n",
       "      <th>SCUB1</th>\n",
       "      <th>FMOD</th>\n",
       "      <th>AMYP</th>\n",
       "      <th>CRIS3</th>\n",
       "      <th>MYDGF</th>\n",
       "      <th>RARR2</th>\n",
       "      <th>...</th>\n",
       "      <th>PGK1</th>\n",
       "      <th>1433Z</th>\n",
       "      <th>SV2A</th>\n",
       "      <th>TRH</th>\n",
       "      <th>GUAD</th>\n",
       "      <th>HV69D</th>\n",
       "      <th>CO7</th>\n",
       "      <th>SERC</th>\n",
       "      <th>AB42/AB40</th>\n",
       "      <th>Ttau (pg/ml)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD_MCI</td>\n",
       "      <td>-0.494309</td>\n",
       "      <td>-0.846909</td>\n",
       "      <td>0.899597</td>\n",
       "      <td>-0.411631</td>\n",
       "      <td>0.111899</td>\n",
       "      <td>0.620927</td>\n",
       "      <td>-0.120125</td>\n",
       "      <td>-0.763607</td>\n",
       "      <td>-0.840882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598239</td>\n",
       "      <td>0.812226</td>\n",
       "      <td>0.052515</td>\n",
       "      <td>-2.927328</td>\n",
       "      <td>1.790729</td>\n",
       "      <td>-2.361951</td>\n",
       "      <td>-1.099094</td>\n",
       "      <td>-0.145335</td>\n",
       "      <td>-0.800179</td>\n",
       "      <td>0.620095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD_MCI</td>\n",
       "      <td>-0.400519</td>\n",
       "      <td>1.138241</td>\n",
       "      <td>1.379783</td>\n",
       "      <td>0.074543</td>\n",
       "      <td>1.463598</td>\n",
       "      <td>-0.472183</td>\n",
       "      <td>-2.027509</td>\n",
       "      <td>-0.880584</td>\n",
       "      <td>0.619631</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005253</td>\n",
       "      <td>1.304040</td>\n",
       "      <td>-0.437144</td>\n",
       "      <td>-0.480640</td>\n",
       "      <td>1.084290</td>\n",
       "      <td>1.385088</td>\n",
       "      <td>-0.643078</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>-1.194905</td>\n",
       "      <td>0.612778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD_MCI</td>\n",
       "      <td>1.477217</td>\n",
       "      <td>0.363325</td>\n",
       "      <td>-0.206424</td>\n",
       "      <td>0.341163</td>\n",
       "      <td>0.434413</td>\n",
       "      <td>-0.292046</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>0.322811</td>\n",
       "      <td>0.941360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.586312</td>\n",
       "      <td>0.312109</td>\n",
       "      <td>-0.630677</td>\n",
       "      <td>-1.548278</td>\n",
       "      <td>-1.212487</td>\n",
       "      <td>0.721655</td>\n",
       "      <td>-0.125949</td>\n",
       "      <td>-1.028790</td>\n",
       "      <td>-0.922864</td>\n",
       "      <td>-0.400673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD_MCI</td>\n",
       "      <td>-0.540071</td>\n",
       "      <td>1.850655</td>\n",
       "      <td>2.466744</td>\n",
       "      <td>1.066619</td>\n",
       "      <td>-0.729014</td>\n",
       "      <td>0.350433</td>\n",
       "      <td>-0.440646</td>\n",
       "      <td>0.627074</td>\n",
       "      <td>-0.382661</td>\n",
       "      <td>...</td>\n",
       "      <td>2.430789</td>\n",
       "      <td>2.351507</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>-0.221895</td>\n",
       "      <td>-0.157784</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>0.377590</td>\n",
       "      <td>1.676169</td>\n",
       "      <td>-0.824182</td>\n",
       "      <td>1.417685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD_MCI</td>\n",
       "      <td>-0.025974</td>\n",
       "      <td>-0.712422</td>\n",
       "      <td>0.880565</td>\n",
       "      <td>-0.992573</td>\n",
       "      <td>-0.468207</td>\n",
       "      <td>0.753878</td>\n",
       "      <td>-1.324054</td>\n",
       "      <td>1.313589</td>\n",
       "      <td>-0.524040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011173</td>\n",
       "      <td>0.638534</td>\n",
       "      <td>0.937442</td>\n",
       "      <td>1.206685</td>\n",
       "      <td>2.540706</td>\n",
       "      <td>-0.289008</td>\n",
       "      <td>-1.112227</td>\n",
       "      <td>1.196369</td>\n",
       "      <td>-0.326241</td>\n",
       "      <td>0.223861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>PD_MCI_LBD</td>\n",
       "      <td>-0.823057</td>\n",
       "      <td>-0.200307</td>\n",
       "      <td>0.758423</td>\n",
       "      <td>0.048004</td>\n",
       "      <td>0.263547</td>\n",
       "      <td>-1.371947</td>\n",
       "      <td>0.585728</td>\n",
       "      <td>3.599443</td>\n",
       "      <td>1.269535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.576836</td>\n",
       "      <td>-0.086893</td>\n",
       "      <td>-0.150382</td>\n",
       "      <td>0.022824</td>\n",
       "      <td>1.056651</td>\n",
       "      <td>0.803522</td>\n",
       "      <td>-0.419239</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.404536</td>\n",
       "      <td>-0.570070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>PD_MCI_LBD</td>\n",
       "      <td>-0.253150</td>\n",
       "      <td>1.698337</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.360982</td>\n",
       "      <td>1.162127</td>\n",
       "      <td>0.311244</td>\n",
       "      <td>1.255747</td>\n",
       "      <td>1.566336</td>\n",
       "      <td>1.376595</td>\n",
       "      <td>...</td>\n",
       "      <td>1.427066</td>\n",
       "      <td>0.883562</td>\n",
       "      <td>1.311786</td>\n",
       "      <td>0.150299</td>\n",
       "      <td>0.481897</td>\n",
       "      <td>-0.274526</td>\n",
       "      <td>1.669666</td>\n",
       "      <td>0.133994</td>\n",
       "      <td>-1.113026</td>\n",
       "      <td>2.298326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>PD_MCI_LBD</td>\n",
       "      <td>-1.521499</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>0.650621</td>\n",
       "      <td>-0.099473</td>\n",
       "      <td>-2.140942</td>\n",
       "      <td>-1.771112</td>\n",
       "      <td>0.620966</td>\n",
       "      <td>-1.443248</td>\n",
       "      <td>-0.200206</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.311166</td>\n",
       "      <td>0.237034</td>\n",
       "      <td>-0.144658</td>\n",
       "      <td>0.495978</td>\n",
       "      <td>-0.018277</td>\n",
       "      <td>0.334649</td>\n",
       "      <td>1.224290</td>\n",
       "      <td>-2.014594</td>\n",
       "      <td>-0.006193</td>\n",
       "      <td>0.201909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>PD_MCI_LBD</td>\n",
       "      <td>-0.133024</td>\n",
       "      <td>-0.418209</td>\n",
       "      <td>-0.057166</td>\n",
       "      <td>-0.654956</td>\n",
       "      <td>0.883038</td>\n",
       "      <td>0.043402</td>\n",
       "      <td>-0.075012</td>\n",
       "      <td>0.523597</td>\n",
       "      <td>0.965335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245195</td>\n",
       "      <td>-0.202206</td>\n",
       "      <td>0.457010</td>\n",
       "      <td>0.319129</td>\n",
       "      <td>0.255220</td>\n",
       "      <td>-0.283393</td>\n",
       "      <td>0.534689</td>\n",
       "      <td>1.489452</td>\n",
       "      <td>-0.814314</td>\n",
       "      <td>-0.350550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>PD_MCI_LBD</td>\n",
       "      <td>-2.296809</td>\n",
       "      <td>-0.445165</td>\n",
       "      <td>-0.333903</td>\n",
       "      <td>1.212097</td>\n",
       "      <td>-0.126415</td>\n",
       "      <td>0.192415</td>\n",
       "      <td>-0.191475</td>\n",
       "      <td>0.098024</td>\n",
       "      <td>0.888204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.838880</td>\n",
       "      <td>-0.349505</td>\n",
       "      <td>-0.609426</td>\n",
       "      <td>2.346341</td>\n",
       "      <td>-1.233739</td>\n",
       "      <td>0.727822</td>\n",
       "      <td>0.814764</td>\n",
       "      <td>-0.762460</td>\n",
       "      <td>-1.657107</td>\n",
       "      <td>-0.943254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          group     AK1C1       TAU     1433G     SCUB1      FMOD      AMYP  \\\n",
       "0        AD_MCI -0.494309 -0.846909  0.899597 -0.411631  0.111899  0.620927   \n",
       "1        AD_MCI -0.400519  1.138241  1.379783  0.074543  1.463598 -0.472183   \n",
       "2        AD_MCI  1.477217  0.363325 -0.206424  0.341163  0.434413 -0.292046   \n",
       "3        AD_MCI -0.540071  1.850655  2.466744  1.066619 -0.729014  0.350433   \n",
       "4        AD_MCI -0.025974 -0.712422  0.880565 -0.992573 -0.468207  0.753878   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "167  PD_MCI_LBD -0.823057 -0.200307  0.758423  0.048004  0.263547 -1.371947   \n",
       "168  PD_MCI_LBD -0.253150  1.698337  0.520508  0.360982  1.162127  0.311244   \n",
       "169  PD_MCI_LBD -1.521499  0.041839  0.650621 -0.099473 -2.140942 -1.771112   \n",
       "170  PD_MCI_LBD -0.133024 -0.418209 -0.057166 -0.654956  0.883038  0.043402   \n",
       "171  PD_MCI_LBD -2.296809 -0.445165 -0.333903  1.212097 -0.126415  0.192415   \n",
       "\n",
       "        CRIS3     MYDGF     RARR2  ...      PGK1     1433Z      SV2A  \\\n",
       "0   -0.120125 -0.763607 -0.840882  ...  0.598239  0.812226  0.052515   \n",
       "1   -2.027509 -0.880584  0.619631  ...  1.005253  1.304040 -0.437144   \n",
       "2    0.022677  0.322811  0.941360  ... -0.586312  0.312109 -0.630677   \n",
       "3   -0.440646  0.627074 -0.382661  ...  2.430789  2.351507 -0.171098   \n",
       "4   -1.324054  1.313589 -0.524040  ...  1.011173  0.638534  0.937442   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "167  0.585728  3.599443  1.269535  ...  1.576836 -0.086893 -0.150382   \n",
       "168  1.255747  1.566336  1.376595  ...  1.427066  0.883562  1.311786   \n",
       "169  0.620966 -1.443248 -0.200206  ... -1.311166  0.237034 -0.144658   \n",
       "170 -0.075012  0.523597  0.965335  ...  0.245195 -0.202206  0.457010   \n",
       "171 -0.191475  0.098024  0.888204  ... -0.838880 -0.349505 -0.609426   \n",
       "\n",
       "          TRH      GUAD     HV69D       CO7      SERC  AB42/AB40  Ttau (pg/ml)  \n",
       "0   -2.927328  1.790729 -2.361951 -1.099094 -0.145335  -0.800179      0.620095  \n",
       "1   -0.480640  1.084290  1.385088 -0.643078  0.074853  -1.194905      0.612778  \n",
       "2   -1.548278 -1.212487  0.721655 -0.125949 -1.028790  -0.922864     -0.400673  \n",
       "3   -0.221895 -0.157784  0.015305  0.377590  1.676169  -0.824182      1.417685  \n",
       "4    1.206685  2.540706 -0.289008 -1.112227  1.196369  -0.326241      0.223861  \n",
       "..        ...       ...       ...       ...       ...        ...           ...  \n",
       "167  0.022824  1.056651  0.803522 -0.419239  0.137968   0.404536     -0.570070  \n",
       "168  0.150299  0.481897 -0.274526  1.669666  0.133994  -1.113026      2.298326  \n",
       "169  0.495978 -0.018277  0.334649  1.224290 -2.014594  -0.006193      0.201909  \n",
       "170  0.319129  0.255220 -0.283393  0.534689  1.489452  -0.814314     -0.350550  \n",
       "171  2.346341 -1.233739  0.727822  0.814764 -0.762460  -1.657107     -0.943254  \n",
       "\n",
       "[172 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev = pd.read_csv('/Users/mariamb/Desktop/BrainPower/brainpower/data/split_data/dev.csv')\n",
    "data_test = pd.read_csv('/Users/mariamb/Desktop/BrainPower/brainpower/data/split_data/test.csv')\n",
    "metadata = pd.read_csv('/Users/mariamb/Desktop/BrainPower/brainpower/data/metadata.csv')\n",
    "\n",
    "data_dev, data_test = add_biomarkers_as_features(metadata, data_dev, data_test)\n",
    "\n",
    "data_dev, data_test = pre_process_data(data_dev, data_test)\n",
    "\n",
    "dev = data_dev[list_features_plus_biomarkers]\n",
    "dev.insert(0, \"group\", data_dev['group'], True)\n",
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d37436",
   "metadata": {},
   "source": [
    "# Testing different ML models \n",
    "Here I am running the \"applying_ml_model.py\" code as a way to test which classifiers are best\n",
    "\n",
    "Results: Naive bayes = around .5, random_forest= around .66, decision_tree = around .60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660458c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folds</th>\n",
       "      <th>scores</th>\n",
       "      <th>abs_avg_score</th>\n",
       "      <th>std</th>\n",
       "      <th>model</th>\n",
       "      <th>scoring_method</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[0.7625, 0.5750000000000001, 0.7625, 0.6875, 0...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.106975</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>[CO7, SERC]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folds                                             scores  abs_avg_score  \\\n",
       "0     10  [0.7625, 0.5750000000000001, 0.7625, 0.6875, 0...           0.72   \n",
       "\n",
       "        std                     model     scoring_method     features  \n",
       "0  0.106975  RandomForestClassifier()  balanced_accuracy  [CO7, SERC]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_ml_model(dev, 'random_forest', feature_list=list_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bee30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_ml_model(dev, 'naive_bayes', feature_list=list_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_ml_model(dev, 'decision_tree', feature_list=list_features_plus_biomarkers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c186a2",
   "metadata": {},
   "source": [
    "# Running on the entire dev and test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657988e",
   "metadata": {},
   "source": [
    "# Using 18 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_mtrx(dev, data_test, features=list_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec58bc",
   "metadata": {},
   "source": [
    "# Using 18 features + Tau and AB42/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_mtrx(dev, data_test, features=list_features_plus_biomarkers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00359e76",
   "metadata": {},
   "source": [
    "# Using 18 features + AB42/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858469c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_mtrx(dev, data_test, features=list_features_plus_ab42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = data_test[list_features]\n",
    "test_y = data_test['group']\n",
    "\n",
    "dev_X = dev[list_features]\n",
    "dev_y = dev.iloc[:,0] # 0th column is our target\n",
    "\n",
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "model.fit(dev_X, dev_y) \n",
    "print(sklearn.metrics.balanced_accuracy_score(test_y, model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e799e32",
   "metadata": {},
   "source": [
    "# \"One vs. Rest\" ROC curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebb19a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dev = pd.read_csv('/Users/mariamb/Desktop/BrainPower/brainpower/data/split_data/dev.csv')\n",
    "data_test = pd.read_csv('/Users/mariamb/Desktop/BrainPower/brainpower/data/split_data/test.csv')\n",
    "metadata = pd.read_csv('/Users/mariamb/Desktop/BrainPower/brainpower/data/metadata.csv')\n",
    "\n",
    "data_dev, data_test = add_biomarkers_as_features(metadata, data_dev, data_test)\n",
    "\n",
    "\n",
    "for i in feature_options: \n",
    "    roc_curves_one_vs_rest(data_dev, data_test, list_features=i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202d9cc",
   "metadata": {},
   "source": [
    "# \"One vs. One\" ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc8ab4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in feature_options: \n",
    "    roc_curve_one_vs_one(data_dev, data_test, i) #change features u choose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
